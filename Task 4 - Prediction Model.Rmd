---
title: "Milestone Report"
output: html_document
author: M.Welt
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(kableExtra)
```
```{r Cache_functions, echo=FALSE}
# Function to load saved R objects from a .RData file if the file exists
loadObjects <- function(fileName) {
  # Append ".RData" extension to the filename
  filePath <- file.path("cache", paste0(fileName, ".RData"))
  
  # Check if the file exists before attempting to load
  if (file.exists(filePath)) {
    # Load objects into the global environment
    load(filePath, envir = .GlobalEnv)
  }
}
save_objects <- function(objects, file_name) {
  if (!dir.exists("cache")) {
    dir.create("cache", recursive = TRUE)
  } 
  filePath <- file.path("cache", paste0(file_name, ".RData"))
  save(list = objects, file = filePath)
}
# Function to format numbers with thousand separators
format_number <- function(x) {
  if (is.numeric(x)) {
    format(x, big.mark = ",", scientific = FALSE)
  } else {
    x
  }
}

show_table <- function(report, rowNames = TRUE) {
  kable(report, align = rep("r", ncol(report)), row.names = rowNames) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover")) %>%
  column_spec(1:ncol(report), border_right = "1px solid lightgray")
}
```


## Task 4 - Prediction Model
The goal of this exercise is to build and evaluate the first predictive model.  
We will use the n-gram and backoff models we built in previous tasks to build and evaluate the model.   
The goal is to make the model efficient and accurate. 

Tasks to accomplish

 - Build a predictive model based on the previous data modeling steps (the models may be combined in any way).
 - Evaluate the model for efficiency and accuracy - use timing software to evaluate the computational complexity of your model. Evaluate the model accuracy using different metrics like perplexity, accuracy at the first word, second word, and third word.

Questions to consider  

 - How does the model perform for different choices of the parameters and size of the model?
 - How much does the model slow down for the performance you gain?
 - Does perplexity correlate with the other measures of accuracy?
 - Can you reduce the size of the model (number of parameters) without reducing performance?